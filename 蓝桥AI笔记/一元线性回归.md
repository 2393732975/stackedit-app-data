
# 一元线性回归

### 平方损失函数
![输入图片说明](/imgs/2024-04-29/KizZucoo5Ovmyg0j.png)
```
def square_loss(x, y, w0, w1): 
	loss = sum(np.square(y - (w0 + w1*x))) 
	return loss
```
### 最小二乘法
通过对平方损失函数的变量w0和w1分别求偏导，然后置零求得如下：
![输入图片说明](/imgs/2024-04-29/yyxo6pvX4hUGywqF.png)
```
def w_calculator(x, y): 
	n = len(x) 
	w1 = (n*sum(x*y) - sum(x)*sum(y))/(n*sum(x*x) - sum(x)*sum(x)) 
	w0 = (sum(x*x)*sum(y) - sum(x)*sum(x*y))/(n*sum(x*x)-sum(x)*sum(x)) 
	return w0, w1
```
### 线性回归 scikit-learn 实现

```
from sklearn.linear_model import LinearRegression 
form sklearn.l
# 定义线性回归模型 
model = LinearRegression() 
model.fit(x.reshape(len(x), 1), y) # 训练, reshape 操作把数据处理成 fit 能接受的形状 

# 得到模型拟合参数 
model.intercept_, model.coef_
```
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTY2MDA0NDY5MiwtMjAyNzM2MTIwMCwtMT
M1NjE3MTIwNl19
-->