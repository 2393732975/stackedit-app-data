
# 一元线性回归

### 平方损失函数
![输入图片说明](/imgs/2024-04-29/KizZucoo5Ovmyg0j.png)
```
def square_loss(x, y, w0, w1): 
	loss = sum(np.square(y - (w0 + w1*x))) 
	return loss
```
### 最小二乘法
通过对平方损失函数的变量w0和w1分别求偏导，然后置零求得如下：
![输入图片说明](/imgs/2024-04-29/yyxo6pvX4hUGywqF.png)
```
def w_calculator(x, y): 
	n = len(x) 
	w1 = (n*sum(x*y) - sum(x)*sum(y))/(n*sum(x*x) - sum(x)*sum(x)) 
	w0 = (sum(x*x)*sum(y) - sum(x)*sum(x*y))/(n*sum(x*x)-sum(x)*sum(x)) 
	return w0, w1
```
### 线性回归 scikit-learn 实现

```
from sklearn.linear_model import LinearRegression 

# 定义线性回归模型 
model = LinearRegression() 
model.fit(x.reshape(len(x), 1), y) # 训练, reshape 操作把数据处理成 fit 能接受的形状 

# 得到模型拟合参数 
model.intercept_, model.coef_
```
`LinearRegression()` 类
`sklearn.linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)`

- fit_intercept: 默认为 True，计算截距项。
- normalize: 默认为 False，不针对数据进行标准化处理。
- copy_X: 默认为 True，即使用数据的副本进行操作，防止影响原数据。
- n_jobs: 计算时的作业数量。默认为 1，若为 -1 则使用全部 CPU 参与运算。

### 最小二乘法的矩阵推导及实现
![输入图片说明](/imgs/2024-04-29/1w1kFMMMPmSl5PgQ.png)
![输入图片说明](/imgs/2024-04-29/K0OTcRSS6XlSfBof.png)
```
def w_matrix(x, y): 
	w = (x.T * x).I * x.T * y 
	return w
```
### 线性回归预测实战

![输入图片说明](/imgs/2024-04-29/NlBlrVfcjGifnKnk.png)![](https://doc.shiyanlou.com/document-uid214893labid6102timestamp1531366212104.png)
本次实验中，我们不会使用到全部的数据特征。这里，仅选取 `CRIM`, `RM`, `LSTAT` 三个特征用于线性回归模型训练。我们将这三个特征的数据单独拿出来，并且使用 `describe()` 方法查看其描述信息。 `describe()` 统计了每列数据的个数、最大值、最小值、平均数等信息。
```
features = df[['crim', 'rm', 'lstat']] 
features.describe()
```
接下来，我们针对数据集的特征和目标进行分割，分别得到 70% 的训练集和 30% 的测试集。其中，训练集特征、训练集目标、测试集特征和测试集目标分别定义为：`X_train`, `y_train`, `X_test`, `y_test`。
```
target = df['mdev']                   # 目标值数据
split_num = int(len(featrues)*0.7)    # 得到 70% 位置

X_train = featrues[:split_num]		  # 训练集特征
y_train = target[:split_num]		  # 训练集目标

X_test = featrues[split_num:]         # 测试集特征
y_test =target[split_num:]			  # 测试集目标
```
划分完数据集之后，就可以构建并训练模型。同样，这里要用到 `LinearRegression()` 类。
```
model = LinearRegression() # 建立模型 
model.fit(X_train, y_train) # 训练模型
model.coef_, model.intercept_ # 输出训练后的模型参数和截距项
preds = model.predict(X_test) # 输入测试集特征进行预测 
preds # 预测结果
```
#### 评价指标
1. 平均绝对误差(MAE)
绝对误差的平均值, MAE 的值越小，说明模型拥有更好的拟合程度。
![输入图片说明](/imgs/2024-04-29/rtxJAQJDoShJSaTP.png)
```
def mae_value(y_true, y_pred): 
	n = len(y_true) 
	mae = sum(np.abs(y_true - y_pred))/n 
	return mae
```
2. 均方误差（MSE）
表示误差的平方的期望值，MSE 的值越小，说明预测模型拥有更好的精确度。
![输入图片说明](/imgs/2024-04-29/cCLlrVVapRk5k5UJ.png)

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEyMjc1MTAzMTgsLTIwMjczNjEyMDAsLT
EzNTYxNzEyMDZdfQ==
-->