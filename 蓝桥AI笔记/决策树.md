# å†³ç­–æ ‘å’ŒKè¿‘é‚»

### å†³ç­–æ ‘
ç†µï¼ˆentropyï¼‰ï¼š ç†µæŒ‡çš„æ˜¯ä½“ç³»çš„æ··ä¹±çš„ç¨‹åº¦ï¼Œåœ¨ä¸åŒçš„å­¦ç§‘ä¸­ä¹Ÿæœ‰å¼•ç”³å‡ºçš„æ›´ä¸ºå…·ä½“çš„å®šä¹‰ï¼Œæ˜¯å„é¢†åŸŸååˆ†é‡è¦çš„å‚é‡ã€‚ï¼ˆå¤§å¤šæ•°å­¦è¿‡ç‰©ç†åŒ–å­¦çš„äººåº”è¯¥å¾ˆç†Ÿæ‚‰è¿™ä¸ªæ¦‚å¿µï¼Œæ²¡ä»€ä¹ˆå˜åŒ–ã€‚ï¼‰

ä¿¡æ¯è®ºï¼ˆinformation theoryï¼‰ä¸­çš„ç†µï¼ˆé¦™å†œç†µï¼‰ï¼š æ˜¯ä¸€ç§ä¿¡æ¯çš„åº¦é‡æ–¹å¼ï¼Œè¡¨ç¤ºä¿¡æ¯çš„æ··ä¹±ç¨‹åº¦ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼šä¿¡æ¯è¶Šæœ‰åºï¼Œä¿¡æ¯ç†µè¶Šä½ã€‚ï¼ˆè¯´ç™½äº†ä¹Ÿæ˜¯è®²ä¿¡æ¯çš„æ··ä¹±ç¨‹åº¦ï¼Œæˆ‘çš„ç†è§£æ˜¯ï¼šä¸€å †ä¿¡æ¯ä¸­ä¸åŒçš„ç±»å¾ˆå¤šï¼Œè¯´æ˜æ··ä¹±ç¨‹åº¦é«˜ï¼Œç†µå°±é«˜ï¼›ä¸€å †ä¿¡æ¯ä¸­åªæœ‰ä¸€ä¸¤ç§ç±»ï¼Œé‚£ç†µå°±æ¯”è¾ƒä½ã€‚ï¼‰


ä¿¡æ¯å¢ç›Šï¼ˆinformation gainï¼‰ï¼š åœ¨åˆ’åˆ†æ•°æ®é›†å‰åä¿¡æ¯å‘ç”Ÿçš„å˜åŒ–ç§°ä¸ºä¿¡æ¯å¢ç›Šã€‚ï¼ˆå°±æ˜¯åˆ’åˆ†æ•°æ®åˆ°ä¸åŒå­é›†å‰åï¼Œç†µçš„å˜åŒ–ã€‚ï¼‰

#### sklearn.tree.DecisionTreeClassifier ç±»
sklearn.tree.DecisionTreeClassifier ç±»çš„ä¸»è¦å‚æ•°ä¸ºï¼š
-   max_depth æ ‘çš„æœ€å¤§æ·±åº¦ï¼›
-   max_features æœç´¢æœ€ä½³åˆ†åŒºæ—¶çš„æœ€å¤§ç‰¹å¾æ•°ï¼ˆç‰¹å¾å¾ˆå¤šæ—¶ï¼Œè®¾ç½®è¿™ä¸ªå‚æ•°å¾ˆæœ‰å¿…è¦ï¼Œå› ä¸ºåŸºäºæ‰€æœ‰ç‰¹å¾æœç´¢åˆ†åŒºä¼šå¾ˆã€Œæ˜‚è´µã€ï¼‰ï¼›
-   min_samples_leaf å¶èŠ‚ç‚¹çš„æœ€å°‘æ ·æœ¬æ•°ã€‚
```
reg_tree = DecisionTreeRegressor(max_depth=5, random_state=17) 
reg_tree.fit(X_train, y_train) 
reg_tree_pred = reg_tree.predict(X_test)
```
### Kè¿‘é‚»
æœ€è¿‘é‚»æ–¹æ³•ï¼ˆK è¿‘é‚»æˆ– k-NNï¼‰æ˜¯å¦ä¸€ä¸ªéå¸¸æµè¡Œçš„åˆ†ç±»æ–¹æ³•ã€‚å½“ç„¶ï¼Œä¹Ÿå¯ä»¥ç”¨äºå›å½’é—®é¢˜ã€‚å’Œå†³ç­–æ ‘ç±»ä¼¼ï¼Œè¿™æ˜¯æœ€å®¹æ˜“ç†è§£çš„åˆ†ç±»æ–¹æ³•ä¹‹ä¸€ã€‚è¿™ä¸€æ–¹æ³•éµå¾ªç´§å¯†æ€§å‡è¯´ï¼šå¦‚æœæ ·æœ¬é—´çš„è·ç¦»èƒ½ä»¥è¶³å¤Ÿå¥½çš„æ–¹æ³•è¡¡é‡ï¼Œé‚£ä¹ˆç›¸ä¼¼çš„æ ·æœ¬æ›´å¯èƒ½å±äºåŒä¸€åˆ†ç±»ã€‚

k-NN åˆ†ç±»/å›å½’çš„æ•ˆæœå–å†³äºä¸€äº›å‚æ•°ï¼š

-   é‚»å±…æ•° kã€‚
-   æ ·æœ¬ä¹‹é—´çš„è·ç¦»åº¦é‡ï¼ˆå¸¸è§çš„åŒ…æ‹¬ Hammingï¼Œæ¬§å‡ é‡Œå¾—ï¼Œä½™å¼¦å’Œ Minkowski è·ç¦»ï¼‰ã€‚æ³¨æ„ï¼Œå¤§éƒ¨åˆ†è·ç¦»è¦æ±‚æ•°æ®åœ¨åŒä¸€å°ºåº¦ä¸‹ï¼Œä¾‹å¦‚ã€Œè–ªæ°´ã€ç‰¹å¾çš„æ•°å€¼åœ¨åƒçº§ï¼Œã€Œå¹´é¾„ã€ç‰¹å¾çš„æ•°å€¼å´åœ¨ç™¾çº§ï¼Œå¦‚æœç›´æ¥å°†ä»–ä»¬ä¸¢è¿›æœ€è¿‘é‚»æ¨¡å‹ä¸­ï¼Œã€Œå¹´é¾„ã€ç‰¹å¾å°±ä¼šå—åˆ°æ¯”è¾ƒå¤§çš„å½±å“ã€‚
-   é‚»å±…çš„æƒé‡ï¼ˆæ¯ä¸ªé‚»å±…å¯èƒ½è´¡çŒ®ä¸åŒçš„æƒé‡ï¼Œä¾‹å¦‚ï¼Œæ ·æœ¬è¶Šè¿œï¼Œæƒé‡è¶Šä½ï¼‰ã€‚

#### scikit-learn çš„ KNeighborsClassifier ç±»

`sklearn.neighbors.KNeighborsClassifier` ç±»çš„ä¸»è¦å‚æ•°ä¸ºï¼š

-   weightsï¼šå¯è®¾ä¸º uniformï¼ˆæ‰€æœ‰æƒé‡ç›¸ç­‰ï¼‰ï¼Œdistanceï¼ˆæƒé‡å’Œåˆ°æµ‹è¯•æ ·æœ¬çš„è·ç¦»æˆåæ¯”ï¼‰ï¼Œæˆ–ä»»ä½•å…¶ä»–ç”¨æˆ·è‡ªå®šä¹‰çš„å‡½æ•°ã€‚
-   algorithmï¼ˆå¯é€‰ï¼‰ï¼šå¯è®¾ä¸º bruteã€ball_treeã€KD_treeã€autoã€‚è‹¥è®¾ä¸º bruteï¼Œé€šè¿‡è®­ç»ƒé›†ä¸Šçš„ç½‘æ ¼æœç´¢æ¥è®¡ç®—æ¯ä¸ªæµ‹è¯•æ ·æœ¬çš„æœ€è¿‘é‚»ï¼›è‹¥è®¾ä¸º ball_tree æˆ– KD_treeï¼Œæ ·æœ¬é—´çš„è·ç¦»å‚¨å­˜åœ¨æ ‘ä¸­ï¼Œä»¥åŠ é€Ÿå¯»æ‰¾æœ€è¿‘é‚»ï¼›è‹¥è®¾ä¸º autoï¼Œå°†åŸºäºè®­ç»ƒé›†è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å¯»æ‰¾æœ€è¿‘é‚»çš„æ–¹æ³•ã€‚
-   leaf_sizeï¼ˆå¯é€‰ï¼‰ï¼šè‹¥å¯»æ‰¾æœ€è¿‘é‚»çš„ç®—æ³•æ˜¯ BallTree æˆ– KDTreeï¼Œåˆ™åˆ‡æ¢ä¸ºç½‘æ ¼æœç´¢æ‰€ç”¨çš„é˜ˆå€¼ã€‚
-   metricï¼šå¯è®¾ä¸º minkowskiã€manhattanã€euclideanã€chebyshev æˆ–å…¶ä»–ã€‚


### éªŒè¯æ¨¡å‹çš„è´¨é‡
-   ç•™ç½®æ³•ã€‚ä¿ç•™ä¸€å°éƒ¨åˆ†æ•°æ®ï¼ˆä¸€èˆ¬æ˜¯ 20% åˆ° 40%ï¼‰ä½œä¸ºç•™ç½®é›†ï¼Œåœ¨å…¶ä½™æ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹ï¼ˆåŸæ•°æ®é›†çš„ 60%-80%ï¼‰ï¼Œç„¶ååœ¨ç•™ç½®é›†ä¸ŠéªŒè¯æ¨¡å‹çš„è´¨é‡ã€‚
-   äº¤å‰éªŒè¯ã€‚æœ€å¸¸è§çš„æƒ…å½¢æ˜¯ k æŠ˜äº¤å‰éªŒè¯ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚
![è¾“å…¥å›¾ç‰‡è¯´æ˜](/imgs/2024-04-30/0AH8fYoa5r1uiQtZ.png)
åœ¨ k æŠ˜äº¤å‰éªŒè¯ä¸­ï¼Œæ¨¡å‹åœ¨åŸæ•°æ®é›†çš„ ğ¾âˆ’1Kâˆ’1 ä¸ªå­é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼ˆä¸Šå›¾ç™½è‰²éƒ¨åˆ†ï¼‰ï¼Œç„¶ååœ¨å‰©ä¸‹çš„ 1 ä¸ªå­é›†ä¸ŠéªŒè¯è¡¨ç°ï¼Œé‡å¤è®­ç»ƒå’ŒéªŒè¯çš„è¿‡ç¨‹ï¼Œæ¯æ¬¡ä½¿ç”¨ä¸åŒçš„å­é›†ï¼ˆä¸Šå›¾æ©™è‰²éƒ¨åˆ†ï¼‰ï¼Œæ€»å…±è¿›è¡Œ K æ¬¡ï¼Œç”±æ­¤å¾—åˆ° K ä¸ªæ¨¡å‹è´¨é‡è¯„ä¼°æŒ‡æ•°ï¼Œé€šå¸¸ç”¨è¿™äº›è¯„ä¼°æŒ‡æ•°çš„æ±‚å’Œå¹³å‡æ•°æ¥è¡¡é‡åˆ†ç±»/å›å½’æ¨¡å‹çš„æ€»ä½“è´¨é‡ã€‚

ç›¸æ¯”ç•™ç½®æ³•ï¼Œäº¤å‰éªŒè¯èƒ½æ›´å¥½åœ°è¯„ä¼°æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„è¡¨ç°ã€‚ç„¶è€Œï¼Œå½“ä½ æœ‰å¤§é‡æ•°æ®æ—¶ï¼Œäº¤å‰éªŒè¯å¯¹æœºå™¨è®¡ç®—èƒ½åŠ›çš„è¦æ±‚ä¼šå˜å¾—å¾ˆé«˜ã€‚

### æ¯”è¾ƒåœ¨å†³ç­–æ ‘å’Œæœ€è¿‘é‚»æ–¹æ³•ï¼ˆé€šè¿‡å®ä¾‹ï¼‰

```
# è¯»å…¥æ•°æ®
import pandas as pd 
df = pd.read_csv( 'https://labfile.oss.aliyuncs.com/courses/1283/telecom_churn.csv') 
df['International plan'] = pd.factorize(df['International plan'])[0] 
df['Voice mail plan'] = pd.factorize(df['Voice mail plan'])[0] 
df['Churn'] = df['Churn'].astype('int') 
states = df['State'] 
y = df['Churn'] 
df.drop(['State', 'Churn'], axis=1, inplace=True)
```
ç•™ç½®æ³•ï¼š
æ¥ä¸‹æ¥ï¼Œè®­ç»ƒ 2 ä¸ªæ¨¡å‹ï¼šå†³ç­–æ ‘å’Œ k-NNã€‚ä¸€å¼€å§‹ï¼Œæˆ‘ä»¬å¹¶ä¸çŸ¥é“å¦‚ä½•è®¾ç½®æ¨¡å‹å‚æ•°èƒ½ä½¿æ¨¡å‹è¡¨ç°å¥½ï¼Œæ‰€ä»¥å¯ä»¥ä½¿ç”¨éšæœºå‚æ•°æ–¹æ³•ï¼Œå‡å®šæ ‘æ·±ï¼ˆmax_deptï¼‰ä¸º 5ï¼Œè¿‘é‚»æ•°é‡ï¼ˆn_neighborsï¼‰ä¸º 10ã€‚
```
from sklearn.model_selection 
import train_test_split, StratifiedKFold from sklearn.neighbors 
import KNeighborsClassifier from sklearn.tree 
import DecisionTreeClassifier 
X_train, X_holdout, y_train, y_holdout = train_test_split(df.values, y, test_size=0.3, random_state=17) 
tree = DecisionTreeClassifier(max_depth=5, random_state=17) 
# åˆ›å»ºäº†ä¸€ä¸ªæœ€å¤§æ·±åº¦ä¸º5çš„å†³ç­–æ ‘åˆ†ç±»å™¨å¯¹è±¡`tree`ï¼Œå¹¶è®¾ç½®äº†éšæœºç§å­ä¸º17ã€‚
knn = KNeighborsClassifier(n_neighbors=10) tree.fit(X_train, y_train) knn.fit(X_train, y_train)
# åˆ›å»ºäº†ä¸€ä¸ªKè¿‘é‚»åˆ†ç±»å™¨å¯¹è±¡`knn`ï¼Œè®¾ç½®äº†é‚»å±…æ•°é‡ä¸º10ã€‚
```
ä½¿ç”¨å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰åœ¨ç•™ç½®é›†ä¸Šè¯„ä»·æ¨¡å‹é¢„æµ‹çš„è´¨é‡ã€‚
```
from sklearn.metrics import accuracy_score 

tree_pred = tree.predict(X_holdout) 
accuracy_score(y_holdout, tree_pred)

knn_pred = knn.predict(X_holdout) 
accuracy_score(y_holdout, knn_pred)
```
ä»ä¸Šå¯çŸ¥ï¼Œå†³ç­–æ ‘çš„å‡†ç¡®ç‡çº¦ä¸º 94%ï¼Œk-NN çš„å‡†ç¡®ç‡çº¦ä¸º 88%ï¼Œäºæ˜¯ä»…ä½¿ç”¨æˆ‘ä»¬å‡å®šçš„éšæœºå‚æ•°ï¼ˆå³æ²¡æœ‰è°ƒå‚ï¼‰ï¼Œå†³ç­–æ ‘çš„è¡¨ç°æ›´å¥½ã€‚


ç°åœ¨ï¼Œä½¿ç”¨äº¤å‰éªŒè¯ç¡®å®šæ ‘çš„å‚æ•°ï¼Œå¯¹æ¯æ¬¡åˆ†å‰²çš„ max_deptï¼ˆæœ€å¤§æ·±åº¦ hï¼‰å’Œ max_featuresï¼ˆæœ€å¤§ç‰¹å¾æ•°ï¼‰è¿›è¡Œè°ƒä¼˜ã€‚`GridSearchCV()` å‡½æ•°å¯ä»¥éå¸¸ç®€å•çš„å®ç°äº¤å‰éªŒè¯ï¼Œä¸‹é¢ç¨‹åºå¯¹æ¯ä¸€å¯¹ max_depth å’Œ max_features çš„å€¼ä½¿ç”¨ 5 æŠ˜éªŒè¯è®¡ç®—æ¨¡å‹çš„è¡¨ç°ï¼Œæ¥ç€é€‰æ‹©å‚æ•°çš„æœ€ä½³ç»„åˆã€‚
```
from sklearn.model_selection import GridSearchCV, cross_val_score 
tree_params = {'max_depth': range(5, 7), 'max_features': range(16, 18)} 
tree_grid = GridSearchCV(tree, tree_params, cv=5, n_jobs=-1, verbose=True) 
tree_grid.fit(X_train, y_train)
```

ç°åœ¨ï¼Œå†æ¬¡ä½¿ç”¨äº¤å‰éªŒè¯å¯¹ k-NN çš„ k å€¼ï¼ˆå³é‚»å±…æ•°ï¼‰è¿›è¡Œè°ƒä¼˜ã€‚
```
from sklearn.pipeline import Pipeline 
from sklearn.preprocessing import StandardScaler 
knn_pipe = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_jobs=-1))]) 
knn_params = {'knn__n_neighbors': range(6, 8)} 
knn_grid = GridSearchCV(knn_pipe, knn_params, cv=5, n_jobs=-1, verbose=True) 
knn_grid.fit(X_train, y_train) 
knn_grid.best_params_, knn_grid.best_score_
```
<!--stackedit_data:
eyJoaXN0b3J5IjpbMjA2MzgxNzAyNCwtMTY3MTg0ODQ0MCwtMT
cxMjU0MDQ2NywxNDUwOTE0ODEwLC05NTYyMDIxNCwtMTkzNjY2
NDgwOCw1NTkyODU1NzZdfQ==
-->