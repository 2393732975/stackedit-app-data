

考点：
数据(数值、文本、图像等)清洗、异常值检测与处理、数据转换、数据标准化/归一化、数据不均衡处理特征提取等数据处理技术。

### 数据清洗
主要分为这几个部分：
1. 处理缺失值 : `fillna（）`填补法

`dropna（）`删除法，特别注意：
`df.dropna(axis=0, how='any', inplace=True)`
-   `axis=0` 表示删除行，`axis=1` 表示删除列。
-   `how='any'` 表示只要该行（或列）中有任何一个缺失值就删除，`how='all'` 表示只有当该行（或列）所有值都是缺失值时才删除。
-   `inplace=True` 表示在原 DataFrame 上直接进行修改，而不返回一个新的 DataFrame。


2.  处理异常值 : `df['salary'] = df['salary'].apply(lambda x: x if 30000 <= x <= 80000 else df['salary'].median()) `
需要记住apply的用法以及lambda表达式
3. 处理重复值 
`# 删除'name'和'city'列上重复的行，只保留第一次出现的行  
df.drop_duplicates(subset=['name', 'city'], keep='first', inplace=True)  `


```text
import pandas as pd  
import numpy as np  
  
# 创建模拟数据，包含重复的行（基于'name'和'city'列）  
data = {  
    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Bob', 'David', 'Eve'],  
    'age': [25, np.nan, 35, 40, 45, 30, 40, 45],  
    'salary': [50000, 60000, np.nan, 75000, 80000, 60000, 120000, 80000],  
    'department': ['HR', 'IT', 'Sales', 'Finance', 'Marketing', 'IT', 'Finance', 'Marketing'],  
    'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago', 'Boston', 'San Francisco', 'Chicago', 'Boston']  
}  
  
# 创建DataFrame  
df = pd.DataFrame(data)  
  
# 查看原始数据  
print("原始数据:")  
print(df)  
  
# 处理缺失值  
# 使用列的均值填充'age'列的缺失值，使用列的中位数填充'salary'列的缺失值  
df['age'].fillna(df['age'].mean(), inplace=True)  
df['salary'].fillna(df['salary'].median(), inplace=True)  

# 处理异常值  
# 假设'salary'列中的值应该在30000到80000之间，我们将其超出这个范围的值视为异常值  
# 并用该列的中位数来替换这些异常值  
df['salary'] = df['salary'].apply(lambda x: x if 30000 <= x <= 80000 else df['salary'].median()) 
  
# 处理重复值  
# 删除'name'和'city'列上重复的行，只保留第一次出现的行  
df.drop_duplicates(subset=['name', 'city'], keep='first', inplace=True)  
  
# 查看清洗后的数据  
print("\n清洗后的数据:")  
print(df)
```
### 异常值检测与处理
主要是介绍z_score的异常值处理方法：

头文件：`from scipy import stats`

函数：`stats.zscore`

具体如下：
```
import pandas as pd
import numpy as np
from scipy import stats
# 创建一个包含异常值的数据集
data = {
'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Bob', 'David', 'Eve'],
'age': [25, np.nan, 35, 40, 45, 30, 40, 45],
'salary': [1, 2, 3, 4, 5, 6, 7, 100],
'department': ['HR', 'IT', 'Sales', 'Finance', 'Marketing', 'IT', 'Finance', 'Marketing'],
'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago', 'Boston', 'San Francisco', 'Chicago', 'Boston']
}
# 创建DataFrame
df = pd.DataFrame(data)
z_scores = np.abs(stats.zscore(df['salary']))
# 定义阈值，通常设为 2或3
threshold = 2
# 找出超过阈值的异常值索引
outlier_indices = np.where(z_scores > threshold)
# 删除异常值所在的行
cleaned_df = df.drop(outlier_indices[0])
cleaned_df
```

### 数据转换
在构造特征的过程中，为了提高机器学习模型的性能和稳定性，通常需要对数据进行特征缩放（如标准化或归一化）、特征编码（如标签编码或 One-Hot 编码）等操作。这样做的目的是将原始数据转化为更有意义的特征，从而使机器学习算法能够更好地理解和利用这些特征来做出准确的预测。

下面是几种常用的特征处理方法：

**数值标准化/归一化**

数值标准化和归一化是特征工程中常用的方法，用于将数值型特征的取值范围归一到一个共同的尺度或范围内，以便更好地处理和分析数据。

#### Z-score 标准化：

Z-score 标准化（Standardization）通过将每个特征值减去该特征的均值，并除以标准差，得到标准化后的特征值。这种方法使得每个特征的均值为 0，标准差为 1。具体计算公式如下：

`𝑧=𝑥−𝜇𝜎`

其中， 𝑥 是原始特征值， 𝜇 是特征的均值， 𝜎 是特征的标准差， 𝑧 是标准化后的特征值。

Z-score 标准化的优点是对数据的分布具有平移和缩放不变性，即标准化后的数据不受数据整体偏移和缩放的影响。

```text
from sklearn.preprocessing import StandardScaler
import numpy as np

# 示例数据
data = np.array([[1, 2], [3, 4], [5, 6]])
print("标准化前的数据：\n", data)

# 创建标准化对象
scaler = StandardScaler()

# 对数据进行标准化
standardized_data = scaler.fit_transform(data)
print("标准化后的数据：\n", standardized_data)
```
输出：
```text
标准化前的数据：
 [[1 2]
 [3 4]
 [5 6]]
标准化后的数据：
 [[-1.22474487 -1.22474487]
 [ 0.          0.        ]
 [ 1.22474487  1.22474487]]
```

#### Min-Max归一化
Min-Max归一化（Normalization）将每个特征值映射到一个指定的范围内，通常是[0，1]或[-1，1]。具体计算公式如下：

𝑥′=𝑥−𝑚𝑖𝑛(𝑥) / 𝑚𝑎𝑥(𝑥)−𝑚𝑖𝑛(𝑥)

其中， 𝑥′ 是归一化后的特征值， 𝑥 是原始特征值， 𝑚𝑖𝑛(𝑥) 和 𝑚𝑎𝑥(𝑥) 分别是特征的最小值和最大值。

Min-Max 归一化的优点是简单易懂，并且可以将数据限制在特定的范围内。它对于一些需要将数据映射到特定范围的算法或可视化方法（如神经网络）会非常合适。

示例代码：
```text
from sklearn.preprocessing import MinMaxScaler
import numpy as np

# 示例数据
data = np.array([[1, 2], [3, 4], [5, 6]])
print("归一化前的数据：\n", data)

# 创建归一化对象，取值范围[0，1]
scaler = MinMaxScaler(feature_range=(0, 1))

# 对数据进行归一化
normalized_data = scaler.fit_transform(data)
print("归一化后的数据：\n", normalized_data)
```
输出结果
```text
归一化前的数据：
 [[1 2]
 [3 4]
 [5 6]]
归一化后的数据：
 [[0.  0. ]
 [0.5 0.5]
 [1.  1. ]]
```

#### **独热编码(One-Hot)编码**
独热编码(One-Hot)编码，又称为一位有效编码，是一种将分类变量转换为二进制向量的表示方法。这种方法主要是采用N位状态寄存器来对N个状态进行编码，每个状态都由其独立的寄存器位表示，并且在任意时候只有一位有效。

One-Hot编码的过程如下：

-   首先，将分类值映射到整数值。例如，如果有三个工作类型，可以将它们映射为0、1和2。
-   然后，每个整数值被表示为二进制向量。对于上述的例子，三个工作类型可以表示为（1，0，0）、（0，1，0）和（0，0，1）。

One-Hot 编码适用于需要将分类变量转换为数值型变量的场景，例如在文本分类、推荐系统以及图像识别中，将文本中的词汇、用户的兴趣爱好以及图像的标签转换为向量表示。此外，在使用逻辑回归、决策树等机器学习算法时，One-Hot 编码可以应用于将离散特征的取值扩展到欧式空间，离散特征的某个取值就对应欧式空间的某个点，从而让特征之间的距离计算更加合理。

示例代码：

```text
import numpy as np

# 假设我们有以下类别标签的列表
categories = ['cat', 'dog', 'bird', 'cat', 'bird']
# 创建一个字典，将类别标签映射到整数值
category_to_int = {'cat': 0, 'dog': 1, 'bird': 2}

# 将类别标签转换为整数值
categories_int = [category_to_int[category] for category in categories]
# 获取唯一类别的数量
num_categories = len(category_to_int)

# 使用NumPy的onehot函数进行One-Hot编码
one_hot_encoded = np.eye(num_categories)[categories_int]

# 打印结果
print("原始类别数据:")
print(categories)
print("\n转换为整数值:")
print(categories_int)
print("\nOne-Hot编码:")
print(one_hot_encoded)
```

输出结果：

```text
原始类别数据:
['cat', 'dog', 'bird', 'cat', 'bird']

转换为整数值:
[0, 1, 2, 0, 2]

One-Hot编码:
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]
 [1. 0. 0.]
 [0. 0. 1.]]
```
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTk2NTE1NzEwOCwtOTAxMzM2MTMsNDQ3OT
gzNzU5LC00NjUxNzYzOTAsLTExNDYxMjQ0MjMsLTIwNTgyMDQ5
ODEsLTI2MDk1Mzg3Miw1MzgzNzc4MTBdfQ==
-->