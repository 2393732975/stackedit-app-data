

考点：
数据(数值、文本、图像等)清洗、异常值检测与处理、数据转换、数据标准化/归一化、数据不均衡处理特征提取等数据处理技术。

### 数据清洗
主要分为这几个部分：
1. 处理缺失值 

```text
import pandas as pd  
import numpy as np  
  
# 创建模拟数据，包含重复的行（基于'name'和'city'列）  
data = {  
    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Bob', 'David', 'Eve'],  
    'age': [25, np.nan, 35, 40, 45, 30, 40, 45],  
    'salary': [50000, 60000, np.nan, 75000, 80000, 60000, 120000, 80000],  
    'department': ['HR', 'IT', 'Sales', 'Finance', 'Marketing', 'IT', 'Finance', 'Marketing'],  
    'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago', 'Boston', 'San Francisco', 'Chicago', 'Boston']  
}  
  
# 创建DataFrame  
df = pd.DataFrame(data)  
  
# 查看原始数据  
print("原始数据:")  
print(df)  
  
# 处理缺失值  
# 使用列的均值填充'age'列的缺失值，使用列的中位数填充'salary'列的缺失值  
df['age'].fillna(df['age'].mean(), inplace=True)  
df['salary'].fillna(df['salary'].median(), inplace=True)  

# 处理异常值  
# 假设'salary'列中的值应该在30000到80000之间，我们将其超出这个范围的值视为异常值  
# 并用该列的中位数来替换这些异常值  
df['salary'] = df['salary'].apply(lambda x: x if 30000 <= x <= 80000 else df['salary'].median()) 
  
# 处理重复值  
# 删除'name'和'city'列上重复的行，只保留第一次出现的行  
df.drop_duplicates(subset=['name', 'city'], keep='first', inplace=True)  
  
# 查看清洗后的数据  
print("\n清洗后的数据:")  
print(df)
```

<!--stackedit_data:
eyJoaXN0b3J5IjpbNTM4Mzc3ODEwXX0=
-->